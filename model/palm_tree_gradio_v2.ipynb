{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"G4Ln5GqjVXAv","executionInfo":{"status":"ok","timestamp":1696658573508,"user_tz":420,"elapsed":6,"user":{"displayName":"Katelyn Fritz","userId":"01025313600614632532"}}},"outputs":[],"source":["MODEL_VERSION = '7'\n","DEMO = True"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"iPyBiXmCe9im","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1696658603731,"user_tz":420,"elapsed":27546,"user":{"displayName":"Katelyn Fritz","userId":"01025313600614632532"}},"outputId":"d025128d-ebbf-4ad6-c871-da89bbd40f6b"},"outputs":[{"output_type":"stream","name":"stderr","text":["Ultralytics YOLOv8.0.134 ðŸš€ Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n","Setup complete âœ… (2 CPUs, 12.7 GB RAM, 26.6/166.8 GB disk)\n"]}],"source":["\n","!pip install ultralytics==8.0.134\n","!pip install gradio\n","\n","from IPython import display\n","display.clear_output()\n","\n","import ultralytics\n","ultralytics.checks()\n","\n","\n","\n"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"cF3NTTAmVDID","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1696658629679,"user_tz":420,"elapsed":20854,"user":{"displayName":"Katelyn Fritz","userId":"01025313600614632532"}},"outputId":"e89ed3b3-e5d1-41fe-9dd0-138c10e10b43"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","Mounted at /content/drive\n"]}],"source":["import os\n","HOME = os.getcwd()\n","HOME = '/content'\n","print(HOME)\n","\n","from google.colab import drive\n","GOOGLE_DRIVE = f'{HOME}/drive'\n","drive.mount(GOOGLE_DRIVE)"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"gzQunGhHVQZh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1696658630839,"user_tz":420,"elapsed":3,"user":{"displayName":"Katelyn Fritz","userId":"01025313600614632532"}},"outputId":"5b031cc6-265c-4dc5-d1d1-fbf3dd039868"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/experiments/7\n"]}],"source":["class Experiment:\n","  '''\n","  Google drive path:\n","\n","  PROJECT_DRIVE = MyDrive/ai/projects/palmtree\n","  EXPERIMENT_DRIVE = MyDrive/ai/projects/palmtree/experiments\n","  UPLOAD_DRIVE = MyDrive/ai/projects/palmtree/uploads\n","  DATASET_DRIVE = MyDrive/ai/projects/palmtree/datasets\n","  DEMO_IMAGES_DRIVE = MyDrive/ai/projects/palmtree/demo/images\n","\n","  '''\n","  EPOCHS = 200\n","  IMGSZ = 640\n","  CONFIDENT = 0.15\n","  MODEL_NAME = \"yolov8s\"\n","  EXPERIMENT_HOME = f'{HOME}/experiments/{MODEL_VERSION}'\n","  DATASET_HOME = f'{HOME}/datasets/palm-tree-detection-{MODEL_VERSION}'\n","  WEIGHTS_HOME = f'{HOME}/weights/{MODEL_VERSION}'\n","  DEMO_HOME = f'{HOME}/demo'\n","  IMAGES_DEMO_HOME = f'{DEMO_HOME}/images'\n","  VIDEOS_DEMO_HOME = f'{DEMO_HOME}/videos'\n","\n","\n","  PROJECT_DRIVE = f'{GOOGLE_DRIVE}/MyDrive/ai/projects/palmtree'\n","  EXPERIMENT_DRIVE = f'{PROJECT_DRIVE}/experiments/{MODEL_VERSION}'\n","  DATASET_DRIVE = f'{PROJECT_DRIVE}/datasets/palm-tree-detection-{MODEL_VERSION}'\n","  WEIGHTS_DRIVE = f'{PROJECT_DRIVE}/weights/{MODEL_VERSION}'\n","  DEMO_DRIVE = f'{PROJECT_DRIVE}/demo'\n","  IMAGES_DEMO_DRIVE = f'{DEMO_DRIVE}/images'\n","  VIDEOS_DEMO_DRIVE = f'{DEMO_DRIVE}/images'\n","\n","  PROJECT_SHARED = f'{GOOGLE_DRIVE}/MyDrive/ai/shared/palmtree'\n","  DEMO_SHARED = f'{PROJECT_SHARED}/demo'\n","  IMAGES_DEMO_SHARED = f'{DEMO_SHARED}/images'\n","  VIDEOS_DEMO_SHARED = f'{DEMO_SHARED}/videos'\n","  WEIGHTS_SHARED = f'{PROJECT_SHARED}/weights/{MODEL_VERSION}'\n","\n","  DEMO_SOURCE = DEMO_SHARED if DEMO else DEMO_DRIVE\n","  WEIGHTS_SOURCE = WEIGHTS_SHARED if DEMO else WEIGHTS_DRIVE\n","\n","\n","print(Experiment.EXPERIMENT_HOME)\n"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"gXOIphW9Vkjc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1696658651325,"user_tz":420,"elapsed":15152,"user":{"displayName":"Katelyn Fritz","userId":"01025313600614632532"}},"outputId":"225e095f-de20-4303-aef2-4c5558552822"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","/content/drive/MyDrive/ai/shared/palmtree/weights/7\n","/content/drive/MyDrive/ai/shared/palmtree/demo\n"]}],"source":["%cd {HOME}\n","%mkdir -p {HOME}/weights/\n","%mkdir -p {HOME}/demo/\n","\n","print(Experiment.WEIGHTS_SOURCE)\n","print(Experiment.DEMO_SOURCE)\n","\n","\n","!cp -fpR {Experiment.WEIGHTS_SOURCE} /content/weights/\n","!cp -fpR {Experiment.DEMO_SOURCE} /content/\n"]},{"cell_type":"code","source":["from ultralytics import YOLO\n","#model = YOLO(f'{Experiment.WEIGHTS_HOME}/best.pt')\n","model = YOLO(f'/content/runs/detect/train/weights/best.pt')\n","\n","model.export(format='coreml', nms=True)#, weights_dir='/content/runs/detect/train/weights')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uUBseuLPvGWz","executionInfo":{"status":"ok","timestamp":1696659193644,"user_tz":420,"elapsed":8604,"user":{"displayName":"Katelyn Fritz","userId":"01025313600614632532"}},"outputId":"bcd141bf-149c-4a16-e569-3e6be6e662a2"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":["Ultralytics YOLOv8.0.134 ðŸš€ Python-3.10.12 torch-2.0.1+cu118 CPU\n","Model summary (fused): 168 layers, 11127906 parameters, 0 gradients\n","\n","\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from /content/runs/detect/train/weights/best.pt with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 10, 8400) (21.5 MB)\n","\n","\u001b[34m\u001b[1mCoreML:\u001b[0m starting export with coremltools 7.0...\n","WARNING:coremltools:When both 'convert_to' and 'minimum_deployment_target' not specified, 'convert_to' is set to \"mlprogram\" and 'minimum_deployment_targer' is set to ct.target.iOS15 (which is same as ct.target.macOS12). Note: the model will not run on systems older than iOS15/macOS12/watchOS8/tvOS15. In order to make your model run on older system, please set the 'minimum_deployment_target' to iOS14/iOS13. Details please see the link: https://coremltools.readme.io/docs/unified-conversion-api#target-conversion-formats\n","WARNING:coremltools:Tuple detected at graph output. This will be flattened in the converted model.\n","Converting PyTorch Frontend ==> MIL Ops: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 524/526 [00:00<00:00, 3648.98 ops/s]\n","Running MIL frontend_pytorch pipeline: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 205.23 passes/s]\n","Running MIL default pipeline: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:02<00:00, 26.18 passes/s] \n","Running MIL backend_mlprogram pipeline: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:00<00:00, 326.66 passes/s]\n","\u001b[34m\u001b[1mCoreML Pipeline:\u001b[0m starting pipeline with coremltools 7.0...\n","\u001b[34m\u001b[1mCoreML:\u001b[0m export failure âŒ 7.3s: MLModel of type mlProgram cannot be loaded just from the model spec object. It also needs the path to the weights file. Please provide that as well, using the 'weights_dir' argument.\n"]},{"output_type":"execute_result","data":{"text/plain":["[]"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":804},"id":"RV_RgEj9mwpU","outputId":"615a7427-2c94-4835-fc42-d5052e6ca45d"},"outputs":[{"name":"stderr","output_type":"stream","text":["<ipython-input-13-09bce1a52c96>:54: GradioDeprecationWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n","  inputs=[gr.inputs.Image(type='pil', label=\"Original Image\"),\n","<ipython-input-13-09bce1a52c96>:54: GradioDeprecationWarning: `optional` parameter is deprecated, and it has no effect\n","  inputs=[gr.inputs.Image(type='pil', label=\"Original Image\"),\n","<ipython-input-13-09bce1a52c96>:56: GradioDeprecationWarning: Usage of gradio.outputs is deprecated, and will not be supported in the future, please import your components from gradio.components\n","  outputs=[gr.outputs.Image(type=\"pil\", label=\"Output Image\"),\n","<ipython-input-13-09bce1a52c96>:57: GradioDeprecationWarning: Usage of gradio.outputs is deprecated, and will not be supported in the future, please import your components from gradio.components\n","  gr.outputs.Textbox()],\n","<ipython-input-13-09bce1a52c96>:65: GradioUnusedKwargWarning: You have unused kwarg parameters in PlayableVideo, please remove them: {'type': 'file'}\n","  inputs=[gr.PlayableVideo(type='file'), gr.Slider(0.0, 1.0, 0.5)],\n","/usr/local/lib/python3.10/dist-packages/gradio/blocks.py:956: UserWarning: api_name predict already exists, using predict_1\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n","Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n","\n","To create a public link, set `share=True` in `launch()`.\n"]},{"data":{"application/javascript":["(async (port, path, width, height, cache, element) => {\n","                        if (!google.colab.kernel.accessAllowed && !cache) {\n","                            return;\n","                        }\n","                        element.appendChild(document.createTextNode(''));\n","                        const url = await google.colab.kernel.proxyPort(port, {cache});\n","\n","                        const external_link = document.createElement('div');\n","                        external_link.innerHTML = `\n","                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n","                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n","                                    https://localhost:${port}${path}\n","                                </a>\n","                            </div>\n","                        `;\n","                        element.appendChild(external_link);\n","\n","                        const iframe = document.createElement('iframe');\n","                        iframe.src = new URL(path, url).toString();\n","                        iframe.height = height;\n","                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n","                        iframe.width = width;\n","                        iframe.style.border = 0;\n","                        element.appendChild(iframe);\n","                    })(7860, \"/\", \"100%\", 500, false, window.element)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"}],"source":["from PIL import Image\n","import gradio as gr\n","import torch\n","from ultralytics import YOLO\n","import glob\n","import os\n","import shutil\n","\n","model = YOLO(f'{Experiment.WEIGHTS_HOME}/best.pt')\n","\n","def yolo_image(im, confident, size=Experiment.IMGSZ):\n","    g = (size / max(im.size))  # gain\n","    im = im.resize((int(x * g) for x in im.size), Image.LANCZOS)\n","\n","    results = model.predict(im, conf=confident)\n","    im_array = results[0].plot()  # updates results.imgs with boxes and labels\n","    imo = Image.fromarray(im_array[..., ::-1])  # RGB\n","\n","    return imo\n","\n","\n","def yolo_video(im, confident, size=Experiment.IMGSZ):\n","  print(confident)\n","  print(size)\n","  print(im)\n","  file_name = os.path.basename(im)\n","  base_name = os.path.splitext(file_name)[0]\n","  file_name = base_name + \".avi\"\n","\n","  if os.path.exists('/content/demo/runs'):\n","    shutil.rmtree('/content/demo/runs')\n","\n","  results = model.predict(im, conf=confident, save=True, project='/content/demo', name='runs')\n","  final_video = f'/content/demo/runs/{file_name}'\n","  return final_video\n","\n","\n","\n","gr_image = gr.Interface(\n","    fn=yolo_image,\n","    inputs=[gr.inputs.Image(type='pil', label=\"Original Image\"),\n","            gr.Slider(0.0, 1.0, 0.5)],\n","    outputs=gr.outputs.Image(type=\"pil\", label=\"Output Image\"),\n","    title=\"Palm Oil Tree detection\",\n","    description=\"Upload an image or click an example image to use.\",\n","    examples=list(map(lambda x: [x], glob.glob(f'{Experiment.IMAGES_DEMO_HOME}/*.jpg'))),\n","    analytics_enabled=False)\n","\n","gr_video = gr.Interface(\n","    yolo_video,\n","    inputs=[gr.PlayableVideo(type='file'), gr.Slider(0.0, 1.0, 0.5)],\n","    outputs=gr.PlayableVideo(),\n","    title=\"Palm Oil Tree detection\",\n","    description=\"Upload a video or click an example video to use.\",\n","    examples=list(map(lambda x: [x], glob.glob(f'{Experiment.VIDEOS_DEMO_HOME}/*.mp4'))),\n","    analytics_enabled=False)\n","\n","\n","demo = gr.TabbedInterface([gr_image, gr_video], [\"Image detection\", \"Video detection\"])\n","demo.launch(debug=True)"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1JyyTHbSk917VdEbgiHDFrhtl03s7N88o","timestamp":1695567663914},{"file_id":"1P-t2ko5ObNZlQ6wgYePZwSoDVnYPqzYG","timestamp":1695269450276},{"file_id":"1wyTr_vdUe3rSSI6m_Nuaw11BnF245C6V","timestamp":1695269174160},{"file_id":"1Mv54WOmTZZ9pzcvuEVWDeib8T9ZeK-wt","timestamp":1695256270533}],"authorship_tag":"ABX9TyPbTl+jC+b2a2j1CODQejzL"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}